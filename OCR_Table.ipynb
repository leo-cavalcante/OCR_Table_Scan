{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "84d461dd-868c-45d4-8717-0060f8bdb8eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/leonardo.cavalcante/Documents/Education - Learning/GitHub/OCR_Table'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e83d3a96-49dd-4580-afe3-a0e4930ea94d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/leonardo.cavalcante/Downloads'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "downloads_path = str(Path.home() / \"Downloads\")\n",
    "os.chdir(downloads_path)\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "14901ac8-12da-4f13-b489-19759957a9be",
   "metadata": {},
   "source": [
    "!sudo apt install tesseract-ocr — yes\n",
    "!pip install pytesseract"
   ]
  },
  {
   "cell_type": "raw",
   "id": "9d0eba5a-5ea4-4b2b-a1fe-7aa87d2d59de",
   "metadata": {},
   "source": [
    "pip install pandas\n",
    "pip install pytesseract\n",
    "pip install xlsxwriter\n",
    "pip install datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "139a5ce4-0ef8-4594-970e-cc565d76e1cf",
   "metadata": {},
   "source": [
    "##### Let’s import all the libraries that will be used in this article"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c12caa13-3962-4bb6-b69e-41186b69c0e5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "55598d48-1afa-4ac3-85e4-d81a09a00948",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import PIL\n",
    "import pytesseract\n",
    "import os\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84c44f83-94cf-406b-bb8a-13ae4542e3a6",
   "metadata": {},
   "source": [
    "##### If you have non-English text data in your tables you will need to download the suitable tesseract data file from this [GitHub Tesseract-OCR link](https://github.com/tesseract-ocr/tessdata).\n",
    "##### After you’ve downloaded it, put it in your tessdata_dir folder, if you set it to be a custom folder like me you’ll also need the following line:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "670f24ca-5dfa-4239-b682-6214192a5f81",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['TESSDATA_PREFIX'] = '/Users/leonardo.cavalcante/Documents/Education - Learning/GitHub/OCR_Table/Languages/'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c29f6aa-1e9a-4ed7-9a45-5d5302b931a4",
   "metadata": {},
   "source": [
    "---\n",
    "##### To check what languages that pytesseract detected used the following print statement:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ac9cecc0-9a24-451b-85f8-626b63be2873",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['eng', 'fra']\n"
     ]
    }
   ],
   "source": [
    "print(pytesseract.get_languages())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77f8811e-9cfb-4b86-b399-8e38ee07ef7f",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f6ba990-107f-4e94-bee8-76e5c2a23a3b",
   "metadata": {},
   "source": [
    "##### Now let’s set the languages we will use and our config for the pytesseract library:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d21aaf67-bd13-4048-b3ca-71e7932ebee4",
   "metadata": {},
   "outputs": [],
   "source": [
    "special_config = '--psm 12 --oem 1'\n",
    "languages_ = \"eng+fra\" # For multiple language use like \"eng+fra+spa+deu+chi_sim\" and so on"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5596df0c-c7a1-41a4-9116-bc242221759d",
   "metadata": {},
   "source": [
    "##### If you want to read more about the config options, please refer to this [link](https://muthu.co/all-tesseract-ocr-options/).\n",
    "The above special_config worked best for my personal needs.\n",
    "\n",
    "Now let’s load the image:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "63d64059-6ad9-4f6d-aa5e-d9a4fdb1b41b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Any image format will do\n",
    "image_path = \"/Users/leonardo.cavalcante/Documents/Education - Learning/GitHub/OCR_Table/Images_to_Treat/Image.webp\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "70fb1316-526d-4227-b3cc-959f25564ae9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# You can use opencv for that option too\n",
    "img_pl=PIL.Image.open(image_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb18c53b-c01b-4050-8f24-581b5e60b639",
   "metadata": {},
   "source": [
    "##### Now let’s use the function pytesseract.image_to_data(), this function returns verbose data including boxes, confidences, line, and page numbers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "adb12737-1762-4f6d-8d2e-66a02fcfbbd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pytesseract.image_to_data(\n",
    "                        img_pl, \n",
    "                        lang=languages_, \n",
    "                        output_type='data.frame', \n",
    "                        config=special_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb937500-1d77-4fef-a852-d7ac8803b90e",
   "metadata": {},
   "source": [
    "##### Now let’s “optimize” the DataFrame so it will hold only data that is important, I will apply the following:\n",
    "\n",
    "Take only the columns: left, top, width, text\n",
    "Sum the columns left and width to create a new column left+width\n",
    "Sort according to top, reindex columns, and drop None values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6ae11e0f-68a2-4d36-bd34-7981a31fae1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimizeDf(old_df: pd.DataFrame) -> pd.DataFrame:\n",
    "    df = old_df[[\"left\", \"top\", \"width\", \"text\"]]\n",
    "    df['left+width'] = df['left'] + df['width']\n",
    "    df = df.sort_values(by=['top'], ascending=True)\n",
    "    df = df.groupby(['top', 'left+width'], sort=False)['text'].sum().unstack('left+width')\n",
    "    df = df.reindex(sorted(df.columns), axis=1).dropna(how='all').dropna(axis='columns', how='all')\n",
    "    df = df.fillna('')\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f781df30-4b78-4901-85f0-13877d198388",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/zp/yqzhd4ds5b39vx46_27blb2m0000gp/T/ipykernel_11284/1445764843.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['left+width'] = df['left'] + df['width']\n"
     ]
    }
   ],
   "source": [
    "data_imp_sort = optimizeDf(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96bb9f75-1a0d-4bdc-b650-2682efc26ab2",
   "metadata": {},
   "source": [
    "##### Now we have the data in our DataFrame called data_imp_sort, if you followed so far you’ll notice that some of the columns and rows are split (for example a cell has the value of “Happy Birthday Jim” but now you have 3 columns one for each of the words), from what I saw the difference between the columns or the rows are up to 10 pixels so I’ll use that as a threshold but you can change it as you like:\n",
    "The below functions are merging the columns and rows respectively:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "547dbcc6-3806-4b20-8518-a912a6f3b657",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mergeDfColumns(old_df: pd.DataFrame, threshold: int = 30, rotations: int = 10) -> pd.DataFrame:\n",
    "  df = old_df.copy()\n",
    "  for j in range(0, rotations):\n",
    "    new_columns = {}\n",
    "    old_columns = df.columns\n",
    "    i = 0\n",
    "    while i < len(old_columns):\n",
    "      if i < len(old_columns) - 1:\n",
    "        # If the difference between consecutive column names is less than the threshold\n",
    "        if any(old_columns[i+1] == old_columns[i] + x for x in range(1, threshold)):\n",
    "          new_col = df[old_columns[i]].astype(str) + df[old_columns[i+1]].astype(str)\n",
    "          new_columns[old_columns[i+1]] = new_col\n",
    "          i = i + 1\n",
    "        else: # If the difference between consecutive column names is greater than or equal to the threshold\n",
    "          new_columns[old_columns[i]] = df[old_columns[i]]\n",
    "      else: # If the current column is the last column\n",
    "        new_columns[old_columns[i]] = df[old_columns[i]]\n",
    "      i += 1\n",
    "    df = pd.DataFrame.from_dict(new_columns).replace('0', '').replace(0, '').replace(np.nan, '')\n",
    "  return df.dropna(axis='columns', how='all').drop_duplicates().reset_index(drop=True)\n",
    "\n",
    "  # df = pd.DataFrame.from_dict(new_columns).replace('', np.nan).dropna(axis='columns', how='all')\n",
    "  # return df.replace(np.nan, '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cbf8446e-dc42-449c-b0b5-584652bf9870",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mergeDfRows(old_df: pd.DataFrame, threshold: int = 15) -> pd.DataFrame:\n",
    "    new_df = old_df.drop_duplicates().iloc[:1]\n",
    "    for i in range(1, len(old_df)):\n",
    "        # If the difference between consecutive index values is less than the threshold\n",
    "        #if abs(old_df.index[i] - old_df.index[i - 1]) < threshold: \n",
    "        #    new_df.iloc[-1] = new_df.iloc[-1].astype(str) + old_df.iloc[i].astype(str)\n",
    "        #else: # If the difference is greater than the threshold, append the current row\n",
    "            # new_df = new_df.append(old_df.iloc[i])\n",
    "            # df = pd.concat([df, pd.DataFrame([new_row])], ignore_index=True)\n",
    "            # new_df = pd.concat([new_df, old_df], ignore_index=True).replace(np.nan, '').replace(0, '').drop_duplicates()\n",
    "        new_df = pd.concat([new_df, old_df], ignore_index=True).replace('0', '').replace(0, '').replace('', np.nan)\n",
    "    return new_df.drop_duplicates().dropna(axis='rows', how='all').reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bb548afc-9037-4c87-ba1a-d33f6372f78c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new_col = mergeDfColumns(data_imp_sort)\n",
    "merged_row_df = mergeDfRows(df_new_col)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ac0ea34-21b8-4c76-97db-9b734ee5b7df",
   "metadata": {},
   "source": [
    "##### Now that the columns and rows are merged according to the threshold, in some of the cases we will still have one or more of the following:\n",
    "Empty rows and/or columns that hold an empty value (not None but still empty, like an empty string)\n",
    "Columns that hold only the value of | with or without empty cells (sometimes if the inner borders are not thick enough it may recognize it as a character)\n",
    "The following function takes care of these scenarios, if you have any additional scenarios you can easily customize the function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "da980e48-cc01-4ae5-892f-87ff8a1b4aed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_df(df):\n",
    "    # Remove columns with all cells holding the same value and its length is 0 or 1\n",
    "    df = df.loc[:, (df != df.iloc[0]).any()]\n",
    "    # Remove rows with empty cells or cells with only the '|' symbol\n",
    "    df = df[(df != '|') & (df != '') & (pd.notnull(df))] \n",
    "    # Remove columns with only empty cells\n",
    "    df = df.dropna(axis=1, how='all')\n",
    "    return df.fillna('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5e540ce1-9c67-473d-9327-506046f390e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_df = clean_df(merged_row_df.copy())\n",
    "cleaned_df.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "e3acf861-1410-48a0-aa3f-6e2a6cc9ce34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cleaned_df.to_excel('Outputs/Excel_Scanned.xlsx', index=False, sheet_name='Scanned')\n",
    "\n",
    "datetime_str = datetime.today().strftime('%Y-%m-%d at %H.%M.%S')\n",
    "cleaned_df.to_excel('Outputs/' + datetime_str + ' - Excel Scanned.xlsx', index=False, sheet_name='Scanned')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "1e14f690-932a-47d7-af19-0b409be5bd46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/leonardo.cavalcante/Documents/Education - Learning/GitHub/OCR_Table\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "cwd = os.getcwd()\n",
    "print(cwd)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
